# iNaturalist 2018 - Full Pipeline Commands

TÃ i liá»‡u nÃ y chá»©a táº¥t cáº£ cÃ¡c cÃ¢u lá»‡nh cáº§n thiáº¿t Ä‘á»ƒ cháº¡y dá»± Ã¡n tá»« Ä‘áº§u vá»›i dataset iNaturalist 2018.

## ğŸ“‹ Tá»•ng quan cÃ¡c bÆ°á»›c

1. **Setup mÃ´i trÆ°á»ng vÃ  download data**
2. **Táº¡o dataset splits**
3. **Train Expert Models** (CE, LogitAdjust, BalancedSoftmax)
4. **Train Gating Network**
5. **Run Plugin Methods** (Balanced & Worst-group)

---

## ğŸš€ CÃ¡c cÃ¢u lá»‡nh chi tiáº¿t

### BÆ°á»›c 1: Setup thÆ° má»¥c vÃ  download data

```bash
# Di chuyá»ƒn vÃ o thÆ° má»¥c project
cd /path/to/capstone_l2r_ess

# Táº¡o thÆ° má»¥c data
mkdir -p data
cd data
```

#### Option A: Sá»­ dá»¥ng aria2c (khuyáº¿n nghá»‹ - nhanh hÆ¡n)

```bash
# Download vá»›i aria2c (16 connections, nhanh hÆ¡n)
aria2c -x 16 -s 16 \
    https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz \
    https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train2018.json.tar.gz \
    https://ml-inat-competition-datasets.s3.amazonaws.com/2018/val2018.json.tar.gz
```

#### Option B: Sá»­ dá»¥ng wget (máº·c Ä‘á»‹nh)

```bash
# Download vá»›i wget
wget https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz
wget https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train2018.json.tar.gz
wget https://ml-inat-competition-datasets.s3.amazonaws.com/2018/val2018.json.tar.gz
```

### BÆ°á»›c 2: Extract vÃ  cleanup

```bash
# Extract cÃ¡c file tar.gz
tar -xvzf train_val2018.tar.gz
tar -xvzf train2018.json.tar.gz
tar -xvzf val2018.json.tar.gz

# XÃ³a cÃ¡c file nÃ©n Ä‘á»ƒ tiáº¿t kiá»‡m dung lÆ°á»£ng
rm train_val2018.tar.gz train2018.json.tar.gz val2018.json.tar.gz

# Quay láº¡i thÆ° má»¥c project root
cd ..
```

### BÆ°á»›c 3: Táº¡o dataset splits

```bash
# Táº¡o thÆ° má»¥c logs náº¿u chÆ°a cÃ³
mkdir -p logs

# Cháº¡y script táº¡o splits
python scripts/create_inaturalist_splits.py \
    --train-json data/train2018.json \
    --val-json data/val2018.json \
    --data-dir data/inaturalist2018/train_val2018 \
    --output-dir data/inaturalist2018_splits \
    --seed 42 \
    --expert-ratio 0.9 \
    --log-file logs/inaturalist2018_splits_$(date +%Y%m%d_%H%M%S).log
```

**Giáº£i thÃ­ch tham sá»‘:**
- `--train-json`: ÄÆ°á»ng dáº«n Ä‘áº¿n file train2018.json
- `--val-json`: ÄÆ°á»ng dáº«n Ä‘áº¿n file val2018.json
- `--data-dir`: ThÆ° má»¥c chá»©a áº£nh (train_val2018)
- `--output-dir`: ThÆ° má»¥c output cho cÃ¡c splits
- `--seed`: Random seed (42)
- `--expert-ratio`: Tá»· lá»‡ train cho expert (0.9 = 90%)
- `--log-file`: File log (tÃ¹y chá»n)

### BÆ°á»›c 4: Train Expert Models

Train cáº£ 3 experts (CE, LogitAdjust, BalancedSoftmax):

```bash
python train_experts.py \
    --dataset inaturalist2018 \
    --expert all \
    --log-file logs/experts_inaturalist2018_$(date +%Y%m%d_%H%M%S).log
```

**Train tá»«ng expert riÃªng láº» (náº¿u cáº§n):**

```bash
# Train CE expert
python train_experts.py \
    --dataset inaturalist2018 \
    --expert ce \
    --log-file logs/expert_ce_inat.log

# Train LogitAdjust expert
python train_experts.py \
    --dataset inaturalist2018 \
    --expert logitadjust \
    --log-file logs/expert_logitadjust_inat.log

# Train BalancedSoftmax expert
python train_experts.py \
    --dataset inaturalist2018 \
    --expert balsoftmax \
    --log-file logs/expert_balsoftmax_inat.log
```

**Quick test (2 epochs, batch size nhá» hÆ¡n):**

```bash
python train_experts.py \
    --dataset inaturalist2018 \
    --expert ce \
    --epochs 2 \
    --batch-size 512 \
    --log-file logs/inat_test.log
```

**Override cÃ¡c tham sá»‘:**

```bash
python train_experts.py \
    --dataset inaturalist2018 \
    --expert all \
    --epochs 200 \
    --lr 0.4 \
    --batch-size 1024 \
    --log-file logs/experts_custom.log
```

### BÆ°á»›c 5: Train Gating Network

```bash
python -m src.train.train_gating_map \
    --dataset inaturalist2018 \
    --routing dense \
    --epochs 100 \
    --batch_size 128 \
    --lr 1e-3 \
    --lambda_lb 1e-2 \
    --log-file logs/gating_inaturalist2018_$(date +%Y%m%d_%H%M%S).log
```

**CÃ¡c tÃ¹y chá»n routing:**

```bash
# Dense routing (táº¥t cáº£ experts)
python -m src.train.train_gating_map \
    --dataset inaturalist2018 \
    --routing dense

# Top-k routing (chá»n k experts tá»‘t nháº¥t)
python -m src.train.train_gating_map \
    --dataset inaturalist2018 \
    --routing top_k \
    --top_k 2
```

### BÆ°á»›c 6: Run Plugin Methods

#### 6a. Balanced Plugin vá»›i Gating (3 experts)

```bash
python run_balanced_plugin_gating.py --dataset inaturalist2018
```

#### 6b. Worst-group Plugin vá»›i Gating (3 experts)

```bash
python run_worst_plugin_gating.py --dataset inaturalist2018
```

#### 6c. Balanced Plugin CE-only (baseline, 1 expert)

```bash
python run_balanced_plugin_ce_only.py --dataset inaturalist2018
```

#### 6d. Worst-group Plugin CE-only (baseline, 1 expert)

```bash
python run_worst_plugin_ce_only.py --dataset inaturalist2018
```

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c sau khi cháº¡y

```
capstone_l2r_ess/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ inaturalist2018/
â”‚   â”‚   â””â”€â”€ train_val2018/          # áº¢nh dataset
â”‚   â”œâ”€â”€ train2018.json             # Train annotations
â”‚   â”œâ”€â”€ val2018.json                # Val annotations
â”‚   â””â”€â”€ inaturalist2018_splits/     # Generated splits
â”‚       â”œâ”€â”€ train_indices.json
â”‚       â”œâ”€â”€ expert_indices.json
â”‚       â”œâ”€â”€ gating_indices.json
â”‚       â”œâ”€â”€ val_indices.json
â”‚       â”œâ”€â”€ test_indices.json
â”‚       â”œâ”€â”€ tunev_indices.json
â”‚       â””â”€â”€ train_class_counts.json
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ experts/
â”‚   â”‚   â””â”€â”€ inaturalist2018/
â”‚   â”‚       â”œâ”€â”€ best_ce_baseline.pth
â”‚   â”‚       â”œâ”€â”€ best_logitadjust_baseline.pth
â”‚   â”‚       â”œâ”€â”€ best_balsoftmax_baseline.pth
â”‚   â”‚       â””â”€â”€ final_calibrated_*.pth
â”‚   â””â”€â”€ gating_map/
â”‚       â””â”€â”€ inaturalist2018/
â”‚           â””â”€â”€ final_gating.pth
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ logits/
â”‚       â””â”€â”€ inaturalist2018/
â”‚           â”œâ”€â”€ ce_baseline/
â”‚           â”œâ”€â”€ logitadjust_baseline/
â”‚           â””â”€â”€ balsoftmax_baseline/
â””â”€â”€ results/
    â””â”€â”€ ltr_plugin/
        â””â”€â”€ inaturalist2018/
            â”œâ”€â”€ ltr_plugin_gating_balanced.json
            â”œâ”€â”€ ltr_plugin_gating_worst.json
            â”œâ”€â”€ ltr_plugin_ce_only_balanced.json
            â”œâ”€â”€ ltr_plugin_ce_only_worst.json
            â””â”€â”€ *.png (plots)
```

---

## âš¡ Cháº¡y tá»± Ä‘á»™ng vá»›i script

Äá»ƒ cháº¡y táº¥t cáº£ cÃ¡c bÆ°á»›c tá»± Ä‘á»™ng, sá»­ dá»¥ng script shell:

```bash
# Cáº¥p quyá»n thá»±c thi
chmod +x run_inaturalist2018_full_pipeline.sh

# Cháº¡y script
bash run_inaturalist2018_full_pipeline.sh
```

Hoáº·c:

```bash
./run_inaturalist2018_full_pipeline.sh
```

---

## ğŸ” Kiá»ƒm tra káº¿t quáº£

### Kiá»ƒm tra experts Ä‘Ã£ train xong:

```bash
ls -lh checkpoints/experts/inaturalist2018/
```

### Kiá»ƒm tra logits Ä‘Ã£ export:

```bash
ls -lh outputs/logits/inaturalist2018/*/
```

### Kiá»ƒm tra gating model:

```bash
ls -lh checkpoints/gating_map/inaturalist2018/
```

### Kiá»ƒm tra plugin results:

```bash
ls -lh results/ltr_plugin/inaturalist2018/
```

---

## âš ï¸ LÆ°u Ã½

1. **Dung lÆ°á»£ng disk**: Dataset iNaturalist 2018 ráº¥t lá»›n (~50GB+ sau khi extract). Äáº£m báº£o cÃ³ Ä‘á»§ dung lÆ°á»£ng.

2. **Thá»i gian training**: 
   - Experts: ~10-20 giá» má»—i expert (tÃ¹y GPU)
   - Gating: ~1-2 giá»
   - Plugin: ~30 phÃºt - 1 giá»

3. **GPU memory**: 
   - ResNet-50 vá»›i batch size 1024 cáº§n GPU cÃ³ Ã­t nháº¥t 16GB VRAM
   - CÃ³ thá»ƒ giáº£m batch size náº¿u thiáº¿u memory

4. **Resume training**: CÃ¡c script tá»± Ä‘á»™ng lÆ°u checkpoint, cÃ³ thá»ƒ resume náº¿u bá»‹ giÃ¡n Ä‘oáº¡n.

5. **Log files**: Táº¥t cáº£ logs Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `logs/` Ä‘á»ƒ dá»… debug.

---

## ğŸ› Troubleshooting

### Lá»—i "Out of memory":
```bash
# Giáº£m batch size
python train_experts.py --dataset inaturalist2018 --batch-size 512
```

### Lá»—i "File not found":
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n Ä‘áº¿n data files
- Äáº£m báº£o Ä‘Ã£ cháº¡y bÆ°á»›c táº¡o splits trÆ°á»›c

### Lá»—i "CUDA out of memory":
- Giáº£m batch size hoáº·c sá»­ dá»¥ng CPU
- ThÃªm `--device cpu` náº¿u cáº§n

---

## ğŸ“Š Monitoring Training

Xem log real-time:

```bash
# Tail log file
tail -f logs/experts_inaturalist2018_*.log

# Hoáº·c vá»›i less
less logs/experts_inaturalist2018_*.log
```







