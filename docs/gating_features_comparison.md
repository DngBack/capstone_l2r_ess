# Gating Features Comparison

## ğŸ“Š Tá»•ng quan thay Ä‘á»•i

ÄÃ£ refactor `GatingFeatureExtractor` trong `src/models/gating_network_map.py` Ä‘á»ƒ sá»­ dá»¥ng approach nháº¹ vÃ  hiá»‡u quáº£ hÆ¡n, tÆ°Æ¡ng tá»± nhÆ° `GatingFeatureBuilder` trong `src/models/gating.py`.

---

## ğŸ”„ Comparison

### **TrÆ°á»›c (Old Implementation)**

**Feature dimension:** `314` (3 experts Ã— 100 classes)

```python
Features = [
    Flattened posteriors:    300 dims (EÃ—C)  # ToÃ n bá»™ posteriors
    Per-expert:                9 dims (3Ã—3)
    Global:                    5 dims
]
```

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Phá»¥ thuá»™c vÃ o sá»‘ classes â†’ khÃ´ng scalable
- âŒ QuÃ¡ nhiá»u redundant information (300/314 = 95% lÃ  posteriors)
- âŒ Overfit risk cao vá»›i dá»¯ liá»‡u nhá»
- âŒ Computational expensive

---

### **Sau (New Implementation)**

**Feature dimension:** `24` (3 experts)

```python
Features = [
    Per-expert (7 Ã— E):      21 dims
        - Entropy
        - Top-K mass
        - Residual mass  
        - Max confidence
        - Top1-Top2 gap
        - Cosine similarity to mean
        - KL divergence to mean
    
    Global (3):              3 dims
        - Mean entropy
        - Mean class variance
        - Std of max confidences
]
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… **KhÃ´ng phá»¥ thuá»™c vÃ o sá»‘ classes** â†’ scalable cho má»i dataset
- âœ… Chá»‰ extract statistics quan trá»ng â†’ informative & compact
- âœ… **92% reduction** (24 vs 314) â†’ Ã­t overfitting, training nhanh hÆ¡n
- âœ… TÃ­nh toÃ¡n nhanh hÆ¡n

---

## ğŸ“ˆ Impact

| Metric | Old | New | Change |
|--------|-----|-----|--------|
| Feature dim | 314 | 24 | **-92%** |
| Computations | High | Low | **Fast** |
| Scalability | No | Yes | âœ… |
| Info density | Low (95% redundant) | High | âœ… |

---

## ğŸ¯ Features Extracted

### **Per-Expert Features (7 Ã— E)**

1. **Entropy** [B, E]
   ```python
   H(p^e) = -Î£ p(y|x) log p(y|x)
   ```
   - Cao â†’ expert khÃ´ng cháº¯c cháº¯n

2. **Top-K mass** [B, E]
   ```python
   Î£_{i=1}^K p_i (top-K probabilities)
   ```
   - Concentration cá»§a probability mass

3. **Residual mass** [B, E]
   ```python
   1 - top-K mass
   ```
   - Long-tail probability

4. **Max confidence** [B, E]
   ```python
   max_y p(y|x)
   ```
   - Confidence cá»§a expert

5. **Top1-Top2 gap** [B, E]
   ```python
   p_1 - p_2
   ```
   - Margin/quyáº¿t Ä‘á»‹nh rÃµ rÃ ng

6. **Cosine similarity** [B, E]
   ```python
   cos(p^e, mean(p))
   ```
   - Äá»“ng thuáº­n vá»›i ensemble

7. **KL divergence** [B, E]
   ```python
   KL(p^e || mean(p))
   ```
   - Disagreement vá»›i ensemble

### **Global Features (3)**

1. **Mean entropy** [B]
   ```python
   H(mean(p))
   ```
   - Ensemble uncertainty

2. **Mean class variance** [B]
   ```python
   mean(var(p, dim=experts))
   ```
   - Disagreement giá»¯a experts

3. **Std of max confidences** [B]
   ```python
   std([max(p^1), ..., max(p^E)])
   ```
   - Confidence dispersion

---

## ğŸ’» Usage

```python
# Usage khÃ´ng Ä‘á»•i
model = GatingNetwork(
    num_experts=3,
    num_classes=100,
    hidden_dims=[256, 128],
    routing='dense'  # or 'top_k'
)

# Forward pass
posteriors = torch.softmax(logits, dim=-1)  # [B, E, C]
weights, aux = model(posteriors)  # [B, E]

# Features Ä‘Æ°á»£c extract tá»± Ä‘á»™ng bÃªn trong
```

---

## âœ… Benefits

1. **Lightweight:** 24 dims vs 314 dims
2. **Scalable:** KhÃ´ng phá»¥ thuá»™c C (num_classes)
3. **Informative:** Chá»‰ giá»¯ statistics quan trá»ng
4. **Fast:** Ãt computation hÆ¡n nhiá»u
5. **Stable:** Ãt overfitting, numerical stable hÆ¡n

---

## ğŸ“ References

- Approach tá»« `src/models/gating.py` (`GatingFeatureBuilder`)
- ÄÆ°á»£c test trong `src/train/train_gating_only.py`
- Literature: Switch Transformers (Fedus et al., 2021)

